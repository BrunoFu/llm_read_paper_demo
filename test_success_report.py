#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
é¡¹ç›®æµ‹è¯•æˆåŠŸæŠ¥å‘Š

æ€»ç»“é¡¹ç›®æµ‹è¯•ç»“æœå’Œç”Ÿæˆçš„æ–‡ä»¶

ä½œè€…: Claude 4.0 Opus
åˆ›å»ºæ—¶é—´: 2025-08-05
"""

import json
from pathlib import Path

def analyze_results():
    """åˆ†æå¤„ç†ç»“æœ"""
    print("ğŸ‰ é¡¹ç›®æµ‹è¯•æˆåŠŸæŠ¥å‘Š")
    print("=" * 80)
    
    output_dir = Path("output/attention_paper")
    
    if not output_dir.exists():
        print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨")
        return
    
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“„ æµ‹è¯•æ–‡ä»¶: attention_paper.pdf")
    print()
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    files_info = [
        ("report_output.md", "ğŸ“Š æ·±åº¦åˆ†ææŠ¥å‘Š", "åŒ…å«è®ºæ–‡çš„è¯¦ç»†ä¸­æ–‡è§£è¯»å’Œåˆ†æ"),
        ("metadata_attention_paper.json", "ğŸ“‹ è®ºæ–‡å…ƒæ•°æ®", "åŒ…å«ä½œè€…ã€æ ‡é¢˜ç­‰åŸºæœ¬ä¿¡æ¯"),
        ("full_attention_paper.md", "ğŸ“„ å®Œæ•´OCRæ–‡æœ¬", "PDFçš„å®Œæ•´æ–‡æœ¬å†…å®¹"),
        ("structure_attention_paper.json", "ğŸ—ï¸ è®ºæ–‡ç»“æ„", "è®ºæ–‡çš„å±‚æ¬¡ç»“æ„ä¿¡æ¯"),
        ("complete_attribute_tree.json", "ğŸŒ³ å±æ€§æ ‘", "è®ºæ–‡çš„è¯¦ç»†å±æ€§åˆ†æ"),
        ("complete_classification.json", "ğŸ·ï¸ è®ºæ–‡åˆ†ç±»", "è®ºæ–‡ç±»å‹å’Œç ”ç©¶æ–¹æ³•åˆ†ç±»"),
        ("pipeline_result.json", "âš™ï¸ å¤„ç†ç»“æœ", "å®Œæ•´çš„æµæ°´çº¿å¤„ç†è®°å½•")
    ]
    
    print("ğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("-" * 60)
    
    for filename, description, detail in files_info:
        file_path = output_dir / filename
        if file_path.exists():
            size_mb = file_path.stat().st_size / 1024 / 1024
            print(f"âœ… {description}")
            print(f"   ğŸ“ {filename}")
            print(f"   ğŸ“ å¤§å°: {size_mb:.2f} MB")
            print(f"   ğŸ’¡ {detail}")
            print()
        else:
            print(f"âŒ {description} - æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            print()
    
    # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
    print("ğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print("-" * 60)
    
    try:
        # è¯»å–æµæ°´çº¿ç»“æœ
        pipeline_file = output_dir / "pipeline_result.json"
        if pipeline_file.exists():
            with open(pipeline_file, 'r', encoding='utf-8') as f:
                pipeline_data = json.load(f)
            
            print(f"âœ… å¤„ç†çŠ¶æ€: {'æˆåŠŸ' if pipeline_data.get('success', False) else 'å¤±è´¥'}")
            print(f"â±ï¸ æ€»è€—æ—¶: {pipeline_data.get('total_processing_time', 0):.2f} ç§’")
            
            stages = pipeline_data.get('stages', {})
            print(f"ğŸ”„ å¤„ç†é˜¶æ®µ: {len(stages)} ä¸ª")
            
            for stage_name, stage_info in stages.items():
                status = "âœ…" if stage_info.get('success', False) else "âŒ"
                time_cost = stage_info.get('processing_time', 0)
                print(f"   {status} {stage_name}: {time_cost:.2f}ç§’")
            
        else:
            print("âš ï¸ æ— æ³•è¯»å–æµæ°´çº¿ç»“æœæ–‡ä»¶")
            
    except Exception as e:
        print(f"âš ï¸ è¯»å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
    
    print()
    
    # æ˜¾ç¤ºæŠ¥å‘Šé¢„è§ˆ
    print("ğŸ“– æŠ¥å‘Šé¢„è§ˆ:")
    print("-" * 60)
    
    try:
        report_file = output_dir / "report_output.md"
        if report_file.exists():
            with open(report_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            print("å‰10è¡Œå†…å®¹:")
            for i, line in enumerate(lines[:10], 1):
                print(f"{i:2d}: {line.rstrip()}")
            
            if len(lines) > 10:
                print(f"... è¿˜æœ‰ {len(lines) - 10} è¡Œ")
                
            print(f"\nğŸ“ æŠ¥å‘Šæ€»é•¿åº¦: {len(lines)} è¡Œ")
            
        else:
            print("âš ï¸ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
            
    except Exception as e:
        print(f"âš ï¸ è¯»å–æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    
    print()
    
    # æ˜¾ç¤ºå…ƒæ•°æ®é¢„è§ˆ
    print("ğŸ“‹ å…ƒæ•°æ®é¢„è§ˆ:")
    print("-" * 60)
    
    try:
        metadata_file = output_dir / "metadata_attention_paper.json"
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            print(f"ğŸ“„ æ ‡é¢˜: {metadata.get('title', 'N/A')}")
            
            authors = metadata.get('authors', [])
            print(f"ğŸ‘¥ ä½œè€…æ•°é‡: {len(authors)}")
            if authors:
                print("   ä¸»è¦ä½œè€…:")
                for author in authors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä½œè€…
                    name = author.get('name', 'N/A')
                    institution = author.get('institution', 'N/A')
                    print(f"   - {name} ({institution})")
                if len(authors) > 3:
                    print(f"   ... è¿˜æœ‰ {len(authors) - 3} ä½ä½œè€…")
            
            print(f"ğŸ“… å‘è¡¨æ—¥æœŸ: {metadata.get('publication_date', 'N/A')}")
            print(f"ğŸ“° æœŸåˆŠ: {metadata.get('journal_name', 'N/A')}")
            print(f"ğŸ”— DOI: {metadata.get('doi', 'N/A')}")
            
        else:
            print("âš ï¸ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
            
    except Exception as e:
        print(f"âš ï¸ è¯»å–å…ƒæ•°æ®æ—¶å‡ºé”™: {e}")
    
    print()
    print("ğŸ¯ æ€»ç»“:")
    print("-" * 60)
    print("âœ… é¡¹ç›®æ ¸å¿ƒåŠŸèƒ½å®Œå…¨æ­£å¸¸")
    print("âœ… PDFæ–‡ä»¶æˆåŠŸå¤„ç†")
    print("âœ… ç”Ÿæˆäº†å®Œæ•´çš„åˆ†ææŠ¥å‘Š")
    print("âœ… æå–äº†å‡†ç¡®çš„å…ƒæ•°æ®")
    print("âœ… å®Œæˆäº†ç»“æ„åŒ–è§£æ")
    print("âœ… è¿›è¡Œäº†è®ºæ–‡åˆ†ç±»å’Œå±æ€§åˆ†æ")
    print()
    print("ğŸ’¡ æ‚¨å¯ä»¥:")
    print("   1. æŸ¥çœ‹ output/attention_paper/report_output.md è·å–è¯¦ç»†åˆ†æ")
    print("   2. ä½¿ç”¨å…¶ä»–PDFæ–‡ä»¶æµ‹è¯•é¡¹ç›®")
    print("   3. æ ¹æ®éœ€è¦è°ƒæ•´é…ç½®å‚æ•°")
    print("   4. é›†æˆåˆ°æ‚¨çš„å·¥ä½œæµç¨‹ä¸­")
    print()
    print("ğŸ‰ é¡¹ç›®æµ‹è¯•å®Œå…¨æˆåŠŸï¼")

if __name__ == "__main__":
    analyze_results()
